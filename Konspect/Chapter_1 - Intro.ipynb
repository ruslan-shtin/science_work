{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Планирование экспериментов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#«Проклятие-размерности»-и-как-его-избежать\" data-toc-modified-id=\"«Проклятие-размерности»-и-как-его-избежать-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>«Проклятие размерности» и как его избежать</a></span></li><li><span><a href=\"#Физические-и-численные-эксперименты\" data-toc-modified-id=\"Физические-и-численные-эксперименты-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Физические и численные эксперименты</a></span></li><li><span><a href=\"#Проектирование-предварительных-экспериментов-(скрининг)\" data-toc-modified-id=\"Проектирование-предварительных-экспериментов-(скрининг)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Проектирование предварительных экспериментов (скрининг)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Оценка-распределения-элементарных-эффектов\" data-toc-modified-id=\"Оценка-распределения-элементарных-эффектов-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Оценка распределения элементарных эффектов</a></span><ul class=\"toc-item\"><li><span><a href=\"#Весовая-функция-крыла-от-10-переменных\" data-toc-modified-id=\"Весовая-функция-крыла-от-10-переменных-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Весовая функция крыла от 10 переменных</a></span></li></ul></li></ul></li><li><span><a href=\"#Разработка-плана-по-осуществлению-выборки\" data-toc-modified-id=\"Разработка-плана-по-осуществлению-выборки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Разработка плана по осуществлению выборки</a></span><ul class=\"toc-item\"><li><span><a href=\"#Стратификация\" data-toc-modified-id=\"Стратификация-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Стратификация</a></span></li><li><span><a href=\"#Латинские-квадраты-и-случайные-Латинские-гиперкубы\" data-toc-modified-id=\"Латинские-квадраты-и-случайные-Латинские-гиперкубы-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Латинские квадраты и случайные Латинские гиперкубы</a></span></li><li><span><a href=\"#Латинские-гиперкубы,-заполняющие-пространство\" data-toc-modified-id=\"Латинские-гиперкубы,-заполняющие-пространство-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Латинские гиперкубы, <em>заполняющие пространство</em></a></span><ul class=\"toc-item\"><li><span><a href=\"#Оптимизация-$\\Phi_q$\" data-toc-modified-id=\"Оптимизация-$\\Phi_q$-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Оптимизация $\\Phi_q$</a></span></li><li><span><a href=\"#Эволюционное-планирование\" data-toc-modified-id=\"Эволюционное-планирование-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Эволюционное планирование</a></span></li><li><span><a href=\"#Подведём-итог-(Putting-it-all-together)\" data-toc-modified-id=\"Подведём-итог-(Putting-it-all-together)-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>Подведём итог (Putting it all together)</a></span></li></ul></li><li><span><a href=\"#Подмножества,-заполняющие-пространство\" data-toc-modified-id=\"Подмножества,-заполняющие-пространство-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Подмножества, заполняющие пространство</a></span><ul class=\"toc-item\"><li><span><a href=\"#Стратегия-№1:-жадный-алгоритм-локального-поиска\" data-toc-modified-id=\"Стратегия-№1:-жадный-алгоритм-локального-поиска-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Стратегия №1: жадный алгоритм локального поиска</a></span></li><li><span><a href=\"#Стратегия-№2:-Перестановочный-алгоритм-(exchange-algorithm)\" data-toc-modified-id=\"Стратегия-№2:-Перестановочный-алгоритм-(exchange-algorithm)-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Стратегия №2: Перестановочный алгоритм (exchange algorithm)</a></span></li></ul></li></ul></li><li><span><a href=\"#Замечание-о-гармонических-откликах\" data-toc-modified-id=\"Замечание-о-гармонических-откликах-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Замечание о гармонических откликах</a></span></li><li><span><a href=\"#Указания-для-дальнейшего-чтения\" data-toc-modified-id=\"Указания-для-дальнейшего-чтения-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Указания для дальнейшего чтения</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача инженерного дизайна: построить \"суррогатную\" модель _f_, которая легко оценивается и имитирует сложное поведение неизвестного объекта __f__.\n",
    "\n",
    "Обозначим $D$ (подмножество k-мерного R-пространства, $D \\subseteq R^k$) - так называемую ___область проектирования___, в которой функция f(x) непрерывна. Но мы можем получать только дискретные значения функции f {$x_i$ → $y_i$ = f($x_i$)|i = 1..n}. Это довольно дорогостоящая процедура. Так что наша задача состоит в том, чтобы используя некоторый набор этих дискретных данных (__выборку__), сконструировать приближённую функцию _f_, с помощью которой можно легко (с малыми затратами по времени и памяти) производить предсказания значения функции f для любого __x__ их $D$.\n",
    "\n",
    "$D$ - область проектирования  \n",
    "__x__ - проектные переменные  \n",
    "__f__ - целевая функция  \n",
    "_f_   - суррогатная модель.  \n",
    "\n",
    "\n",
    "Большая часть этой книги - способы конструирования _f_ по заданной выборке. За исключением нескольких случаев, для которых уже найдены точные математические решения...  \n",
    "Некоторым моделям необходимо минимальное число элементов в выборке _n_...\n",
    "\n",
    "Важно сказать, что сконструированные таким образом функции _f_ по заданной выборке не всегда хорошо обобщаются на всю область $D$. Всё зависит от пришедшей на вход выборки.  \n",
    "Получение этой выборки не всегда зависит от нас: её могли получить исследуя другие вопросы. Однако далее будет описано, как в случае возможности создания своей собственной выборки сделать такую выборку, которая позволит создать хорошо обобщающую данные суррогатную модель _f_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &laquo;Проклятие размерности&raquo; и как его избежать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, чем больше в задаче переменных, тем сложнее будет функция измерения, с помощью которой мы хотим достаточно точно определить местоположение объекта. Заметим, что если некоторый уровень точности определения положения в одномерном пространстве достигается взятием выборки из $n$ позиций, то в $k$-мерном пространстве для достижения такой же точности необходимо взять выборку из $n^k$ точек. Это и есть \"проклятие размерности\". Поэтому важно с самого начала свести количество _проектных переменных_ $k$ к минимуму.  \n",
    "Задача состоит в том, чтобы среди всех переменных выделить существенные. Но сначала нам нужно сделать несколько общих замечаний о физических и вычислительных экспериментах, двух источниках, которые могут быть использованы для получения целевой функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Физические и численные эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существуют 3 источника ошибок, из-за которых результаты эксперимента отклоняются от теоретических расчётов:\n",
    "\n",
    "* __человеческая ошибка__ - осуществляется самим экспериментатором;  \n",
    "* __систематическая ошибка__ - появляется из-за недостаточного соответствия между теорией и экспериментом;\n",
    "* __случайная ошибка__ - появляется из-за наличия погрешности измерений.\n",
    "\n",
    "Главным отличием между последними двумя пунктами является повторяемость. Систематическая составляющая вносит в экспериментальную ошибку всегда одно и то же значение, а случайная - каждый раз будет отличаться, и при большом числе экспериментов она будет принимать как положительные, так и отрицательные значения.  \n",
    "Численные эксперименты (эксперименты, смоделированные на ЭВМ) также подвержены экспериментальной ошибке, возникающей в результате:\n",
    "\n",
    "* __человеческая ошибка__ - 'баги' и ошибки в написанном коде, неверное введённые граничные условия при решении ДУЧП (дифференциального уравнения в частных производных) и т.д.;\n",
    "* __систематическая ошибка__ - например, математическая модель невязкого обтекания тела (аппроксимация, иногда используемая для экономии вычислительного времени) будет недооценивать силы сопротивления, действующие на тело (потому что в течении на самом деле присутствует вязкость). Другой пример - ошибка, вызванная конечностью разрешения численного моделирования (например, ошибка, вызванная малым числом узлов расчётной сетки). Хоть этот тип ошибки может как переоценить значение некоторой величины, так и недооценить, но при повторении эксперимента он сделает точно также.  \n",
    "\n",
    "Таким образом, разница между физическими и численными экспериментами заключается в том, что на вторые не влияет случайная ошибка - численные эксперименты ___детерминированы___.  \n",
    "\n",
    "__Небольшое замечание:__  \n",
    "> Физические экспериментаторы часто используют слово *шум*, имея в виду случайную ошибку. Однако в некоторой литературе по численным экспериментам также встречается слово *шум*, которое должно относится к систематическим ошибкам, потому что там нет случайных.  \n",
    "Чтобы не запутаться, в дальнейшем, когда мы будем говорить об ошибках физических экспериментов, будем писать слово *шум* без кавычек,а когда об ошибках численных экспериментов - будем писать \"шум\" - в кавычках\n",
    ">  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проектирование предварительных экспериментов (скрининг)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы увидели, насколько важно минимизировать число проектных переменных $x_1, x_2, \\ldots, x_k$ перед тем, как мы попытаемся смоделировать целевую функцию $\\mathbf{f}$. Но как нам добиться такого ___скрининга___ (так мы будем называть этот процесс в дальнейшем), чтобы наш анализ всё ещё имел смысл?  \n",
    "Дифференцируемость функции $\\mathbf{f}$ в области проектирования $D$ по каждой переменной:\n",
    "$$ \\frac{\\partial f}{\\partial x_i}|_x $$ является важным критерием для классификации:\n",
    "\n",
    "* если $\\frac{\\partial f}{\\partial x_i}|_x = 0, \\forall x \\in D$, то переменной $x_i$ можно смело пренебречь,\n",
    "* если $\\frac{\\partial f}{\\partial x_i}|_x = const \\neq 0, \\forall x \\in D$, то влияние переменной $x_i$ линейно и аддитивно,\n",
    "* если $\\frac{\\partial f}{\\partial x_i}|_x = g(x_i) \\neq const, \\forall x \\in D$, то $f$ нелинейна по $x_i$,\n",
    "* если $\\frac{\\partial f}{\\partial x_i}|_x = g(x_i),\\forall x \\in D$, где  $g(x_i, x_j, \\ldots) \\neq const$, то $f$ нелинейна по $x_i$ и участвует во взаимодействиях с $x_j, \\ldots$  \n",
    "\n",
    "Приведенная выше классификация является всего лишь терминологической формулировкой, т.к. на практике мы не можем измерить $\\frac{\\partial f}{\\partial x_i}|_x$ во всей области проектирования.\n",
    "Скрининговое исследование - трудная и ресурсоёмкая задача. Однако нет жёсткого правила относительно того, сколько времени должно быть потрачено на скриннинг переменных, т.к. это в значительной степени зависит от задачи.\n",
    "Если мы ожидаем, что многими переменными можно будет пренебречь, то тщательное скрининговое исследование может значительно повысить точность последующей \"суррогатной\" модели. Однако, если есть (инженерные) основания, полагать, что большинство переменных имеют значительное влияние на целевую функцию, то целесообразно сосредоточить усилия на самом моделировании.  \n",
    "О методах скрининга входных переменных написано много статей (Jones et al., 1998). Их принципы работы варьируются в зависимости от допущений, которые они делают относительно целевой функции и переменных. Здесь мы остановимся на алгоритме, который в 1991 году описал Моррис. Почему мы выбрали именно этот алгоритм? Потому что единственное допущение, которое он делает, заключается в том, что целевая функция детерминирована (это общая особенность для большинства вычислительных моделей)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка распределения элементарных эффектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без ограничения общности предположим, что наша область проектирования $D$ является $k$-мерным единичным кубом, т.е. $D=[0,1]^k$. Это предположение упростит дальнейшие рассуждения.  \n",
    "\n",
    "Прежде чем приступить к описанию алгоритма Морриса, нам необходимо определить важное статистическое понятие.\n",
    "Ограничим нашу область проектирования $D$ $k$-мерной $p$-уровневой факториальной сеткой, т.е. $x_i \\in \\{0, \\frac{1}{p-1}, \\frac{2}{p-1}, ... , 1\\}$ для   $i = 1,...,k$. Для заранее заданного значения  $\\mathbf{x} \\in D$ определим ___элементарное воздействие___ от  $x_i$ $d_i(x)$, равное\n",
    "\n",
    "$$ d_i(x)=\\frac{y(x_1,x_2,...,x_{i-1},x_i+\\Delta, x_{i+1},...,x_k)-y(x)}{\\Delta}, $$\n",
    "\n",
    "где $\\Delta = \\frac{\\xi}{p-1}, \\xi \\in \\mathbb{N^*}$ и $x \\in D$ такой, что его компоненты $x_i \\leq 1-\\Delta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод Морриса используется для оценки параметров распределения элементарных воздействий, связанных с каждой переменной.\n",
    "Принцип заключается в том, что большая величина _центральной тенденции_ (мат. ожидания???) указывает на переменную, имеющую сильное влияние на целевую функцию в области проектирования, а большая _мера разброса_ (дисперсии???) указывает на переменную, по которой $\\mathbf{f}$ не линейна и участвует во взаимодействиях с другими переменными.\n",
    "На практике мы оцениваем выборочное среднее (среднее арифметическое??? $\\overline{x} = \\frac{1}{n} \\sum\\limits_{i=1}^n x_i$) и выборочное стандартное отклонение(среднеквадратичное отклонение ??? $\\sigma = \\sqrt{D[x]}$) набора значений $d_i(x)$, рассчитанных в различных частях проектного пространства."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ясно, что желательно сгенерировать предварительный план выборки $\\mathbf{X}$ так, чтобы каждая оценка целевой функции $\\mathbf{f}$ участвовала в вычислении двух элементарных воздействий (вместо одного, как если бы мы использовали случайное распределение $\\mathbf{x}$ и затем добавляли $\\Delta$ к одной из его компонент). Также, план выборки должен дать нам вполне конкретное число (например, $r$) элементарных воздействий для каждой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $\\mathbf{B}$ является ___матрицей выборки___, т.е. матрицей размерности $k+1 \\times k$ состоящей из нулей и единиц с тем свойством, что для каждого столбца $i=\\overline{1,k}$ есть две строки $\\mathbf{B}$, которые отличаются только $i$-ым элементом (далее мы напишем функцию реализующую такую матрицу). Затем мы вычисляем $\\mathbf{B}^*$ - ___случайную ориентацию___ матрицы $\\mathbf{B}$:\n",
    "\n",
    "$$ B^* = \\left(\\mathbf{1}_{k+1,1}x^* + \\frac{\\Delta}{2} \\left[(2B - \\mathbf{1}_{k+1,k})D^* + \\mathbf{1}_{k+1,k} \\right] \\right) P^*, $$\n",
    "\n",
    "где $D^*$ - это $k$-мерная диагональная матрица, где каждый элемент равен +1 или -1 с равной вероятностью, $\\mathbf{1}_{k+1,k}$ - это матрица единиц, $x^*$ - это случайно выбранная точка нашей дискретизированной $p$-уровневой области проектирования (ограниченной по краям $\\Delta$, как было сказано ранее) и $P^*$ - это матрица случайной перестановки столбцов размером $k \\times k$, в которой каждый столбец содержит всего одну единицу, а все остальные элементы равны нулю, при этом у любой пары столбцов единицы стоят в разных строках. Далее приведена реализация данного выражения на языке Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randorient(k,p, xi):\n",
    "    \"\"\"\n",
    "    Генерирует случайную ориентацию скрининговой матрицы.\n",
    "\n",
    "    Вход:\n",
    "        k - число проектных перемненных\n",
    "        p - число дискретных уровней в каждой размерности области проектирования\n",
    "        xi - коэффициент элементарного воздействия(???)\n",
    "\n",
    "    Выход:\n",
    "        Bstar - случайная ориентация матрицы\n",
    "    \"\"\"\n",
    "    \n",
    "    Delta = xi/(p-1)\n",
    "    m = k+1\n",
    "    \n",
    "    # сужение p-уровневой сетки\n",
    "    xs = np.hstack((np.arange(0, 1-Delta, 1/(p-1)),1-Delta))\n",
    "    xsl = len(xs)    \n",
    "    \n",
    "    #Матрица выборки\n",
    "    B = np.zeros((k+1,k))\n",
    "    B[0,:] = np.zeros((1,k))\n",
    "    B[1:,:] = np.tril(np.ones((k,k)))\n",
    "    \n",
    "    #Рандомизация\n",
    "    \n",
    "    #k-мерная диагональная матрица, где каждый элемент \n",
    "    #равен +1 или -1 с равной вероятностью\n",
    "    Dstar = np.diag(np.int64(np.round(np.random.rand(k)))*2-1)\n",
    "    \n",
    "    #Перестановочная матрица\n",
    "    Pstar = np.zeros((k,k))\n",
    "    rp = np.random.permutation(k)\n",
    "    for i in np.arange(k):\n",
    "        Pstar[i][rp[i]] = 1\n",
    "        \n",
    "    \n",
    "    #случайно выбранная точка\n",
    "    xstar = xs[np.int64(np.floor(np.random.rand(k)*xsl))]\n",
    "    xstar = np.reshape(xstar, (1, k))\n",
    "\n",
    "    \n",
    "#   Bstar = np.dot((np.dot(np.ones((m,1)),xstar) + (Delta/2) * (np.dot((2*B - np.ones((m,k))),Dstar) + np.ones(m,k))), Pstar)\n",
    "#   разобъём вычисления на отдельные действия (удобно при отладке)\n",
    "\n",
    "    ones_xstar = np.dot(np.ones((m,1)),xstar)\n",
    "    twoB_minus_ones = 2*B - np.ones((m,k))\n",
    "    B_ones_Dstar = np.dot(twoB_minus_ones, Dstar)    \n",
    "    B_Dstar_plus_ones = B_ones_Dstar + np.ones((m,k))\n",
    "    circle_breakets = ones_xstar + (Delta/2) * B_Dstar_plus_ones\n",
    "\n",
    "    Bstar = np.dot(circle_breakets, Pstar)\n",
    "\n",
    "    return Bstar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить $r$ элементарных воздействий для каждой переменной  план скрининга строится из $r$ случайных ориентаций:\n",
    "$$ X = \\left[\\begin{array}{crl} B^*_1\\\\ B^*_2\\\\ ... \\\\ B^*_r \\end{array}\\right]. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screeningplan(k, p , xi, r):\n",
    "    \"\"\"\n",
    "    Генерирует Моррисовский скрининговый план с заданным \n",
    "    числом элементарных воздействий для каждой переменной\n",
    "    \n",
    "    Вход:\n",
    "        k - число проектных перемненных\n",
    "        p - число дискретных уровней в каждой размерности области проектирования\n",
    "        xi - коэффициент элементарного воздействия(???)\n",
    "        r - число случайных ориентаций (=число элементарных \n",
    "            воздействий на кажду переменную)\n",
    "    Выход:\n",
    "        X - скрининговый план внутри к-мерного куба [0,1]^k\n",
    "    \"\"\"\n",
    "    \n",
    "    X = randorient(k,p,xi)\n",
    "    for i in np.arange(1, r):\n",
    "        X = np.append(X, randorient(k,p,xi), axis=0)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы посчитаем значение функции _f_ для каждой строки $X$. В дальнейшем мы будем хранить эти значения целевой функции в векторе-столбце $t_{r(k+1) \\times 1}$. Взяв по одной случайной ориентации за раз, соседние строки из матрицы скринингового плана и соответствующие значения функции f могут быть вставлены в уравнение (2) для получения $k$ элементарных воздействий (по одному для каждой переменной).  \n",
    "После того как собрана выборка из _r_ элементарных воздейтвий, средние значения выборок и стандартные отклонения выборок могут быть вычислены и представлены на одной и той же диаграмме для сравнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screeningplot(X, Objhandle, Range, xi, p, Labels):\n",
    "    \"\"\"\n",
    "    Генерирует график скрининга переменных элементарных воздействий\n",
    "    Вход:\n",
    "        X - скрининговый план внутри к-мерного куба [0,1]^k\n",
    "        Objhandle - целевая функция\n",
    "        Range - матрица 2 на к (к - число проектных переменных) нижних(первая строка) \n",
    "                и верхних(вторая строка) границ для каждой переменной\n",
    "        p - число дискретных уровней в каждой размерности области проектирования\n",
    "        xi - коэффициент элементарного воздействия(???)\n",
    "        Labels - массив (1 на к) имён переменных\n",
    "    \"\"\"\n",
    "    k = X.shape[1] #число столбцов матрицы X =  число проектных переменных\n",
    "    r = X.shape[0]//k\n",
    "    t = []\n",
    "    \n",
    "    for i in np.arange(X.shape[0]):\n",
    "        X[i,:] = Range[0,:] + X[i,:]*(Range[1,:] - Range[0,:])\n",
    "        t.append(Objhandle(*list(X[i,:])))\n",
    "    \n",
    "\n",
    "    F = np.zeros((k,r))\n",
    "    for i in np.arange(r):\n",
    "        for j in np.arange(i*(k+1), i*(k+1)+k):\n",
    "            F[(np.where(X[j,:] - X[j+1,:] != 0))[0].ravel(),i] = (t[j+1] - t[j])/(xi/(p-1))\n",
    "    \n",
    "        \n",
    "    #вычисляем статистические величины\n",
    "    ssd=[]\n",
    "    sm=[]\n",
    "    for i in np.arange(k):\n",
    "        ssd.append(np.std(F[i,:]))\n",
    "        sm.append(np.mean(F[i,:]))\n",
    "        \n",
    "    size = 10\n",
    "    plt.figure(figsize=(size,size))\n",
    "    plt.xlabel('Sample_means', fontsize=16)\n",
    "    plt.ylabel('Sample_standart_deviations', fontsize=16)\n",
    "    plt.xlim(min(sm), max(sm))\n",
    "    plt.ylim(min(ssd), max(ssd))\n",
    "    \n",
    "    for i in np.arange(k):\n",
    "        plt.text(sm[i],ssd[i],Labels[i], fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def func(Sw, Wfw, A, L, q, l, tc, Nz, Wdg, Wp):\n",
    "    W = 0.036 * Sw**0.758 * Wfw**0.0035 * (A / np.cos(L*np.pi/180)**2)**0.6 * q**0.006 * l**0.04 * (100*tc/np.cos(L*np.pi/180))**(-0.3) * (Nz*Wdg)**0.49 + Sw*Wp\n",
    "    return W\n",
    "\n",
    "k = 10\n",
    "p = 50\n",
    "xi = 1\n",
    "r = 5\n",
    "X = screeningplan(k,p,xi,r)\n",
    "Range = np.array([[150.0, 220.0, 6.0, -10.0, 16.0, 0.5, 0.08, 2.5, 1700.0, 0.025],\n",
    "                  [200.0, 300.0, 10.0, 10.0, 45.0, 1.0, 0.18, 6.0, 2500.0, 0.08]])\n",
    "Labels = ['Sw', 'Wfw', 'A', 'L', 'q', 'l', 'tc', 'Nz', 'Wdg', 'Wp']\n",
    "\n",
    "screeningplot(X, func, Range, xi, p , Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем проиллюстрировать процесс примером инженерного проектирования, стоит упомянуть два сценария, где развертывание описанного выше алгоритма требует особой осторожности.  \n",
    "Во-первых, если размерность k пространства относительно мала и мы можем позволить себе большое значение _r_, то следует иметь в виду повышенную вероятность того, что одна и та же конструкция появится дважды в $X$. Если ответы в точках выборки детерминированы, то, конечно, нет смысла повторять оценку. Эта проблема возникает не особенно часто, так как при скрининге пространств с большими размерностями обычно требуется _большое_ количество элементарных воздействий. \n",
    "Во-вторых, программы численного моделирования иногда не возвращают разумный результат из-за ошибок сетки, неспособности решения дифференциального уравнения в частных производных сходиться и т. д. С точки зрения скрининга это важно, поскольку все случайные ориентации $B^*$  будут под угрозой, если вычисление целевой функции не удаётся для одной из точек.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Весовая функция крыла от 10 переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим следующее аналитическое выражение, используемое в качестве концептуального уровня оценки веса крыла легкого самолета:\n",
    "$$W = 0.036S^{0.758}_wW^{0.0035}_{fw}(\\frac{A}{cos^2\\Lambda})^{0.6}q^{0.006}\\lambda^{0.04}(\\frac{100tc}{cos\\Lambda})^{-0.3}(N_zW_{dg})^{0.49}+S_wW_p.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица 1.1 содержит номенклатуру символов, используемых в уравнении (5), а также набор основных значений, приблизительно представляющих самолет Cessna C172 Skyhawk и несколько произвольно выбранный диапазон для каждой переменной. Эти основные значения и диапазоны были использованы для создания заполненного контурного графика весовой функции (см. рис. 1.1) путем попарного изменения входных данных и сохранения оставшихся переменных на базовом значении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Таблица 1.1.__  Номенклатура примера задачи скрининга с десятью переменными\n",
    "\n",
    "| Символ    | Параметр                                            | Основное значение | Мин.знач | Макс.знач |\n",
    "| ------    | ------------------------                            | ----------------- | -------- | --------- |\n",
    "| $S_w$     | площадь крыла                                       | 174               | 150      | 200       |\n",
    "| $W_{fw}$  | вес топлива в крыле                                 | 252               | 220      | 300       |\n",
    "| $A$       | Соотношение сторон                                  | 7.52              | 6        | 10        |\n",
    "| $\\Lambda$ | Четверть-хордовая развертка (град)                  | 0                 | -10      | 10        |\n",
    "| $q$       | Скоростной напор???                                 | 34                | 16       | 45        |\n",
    "| $\\lambda$ | Коэффициент конусности                              | 0.672             | 0.5      | 1         |\n",
    "| $tc$      | Отношение толщины аэродинамического профиля к хорде | 0.12              | 0.08     | 0.18      |\n",
    "| $N_z$     | Предельный коэффициент нагрузки                     | 3.8               | 2.5      | 6         |\n",
    "| $W_{dg}$  | Полная масса лётной конструкции                     | 2000              | 1700     | 2500      |\n",
    "| $W_p$     | Вес краски                                          | 0.064             | 0.025    | 0.08      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[image 1.1]: ///home/ruslan/Изображения/graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](///home/ruslan/Изображения/graph/150x150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![graph](img/graph.jpg \"график\") -->\n",
    "<img src=\"img/graph.jpg\" alt=\"график\" style=\"width:75%;\"/>\n",
    "\n",
    "__Рис. 1.1.__ Легкий самолет с массой крыла $W$. Каждая плитка показывает контур весовой функции (уравнение (5)) по сравнению с двумя из десяти переменных, а остальные восемь переменных удерживаются на базовом значении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, что же показывает сюжет с точки зрения активности переменных? Как и ожидалось, например, вес на единицу площади поверхности краски $W_p$ не оказывает большого влияния на форму поверхности, тогда как коэффициент нагрузки $N_z$ (который определяет величину максимальной аэродинамической нагрузки на крыло) явно очень активен и участвует во взаимодействии с другими переменными. Классическим примером является взаимодействие с соотношением сторон $A$:  область в верхнем правом углу веса по сравнению с $A$ и $N_z$ указывает на тяжелое крыло для высоких соотношений сторон и больших g-сил (это причина, по которой высоко маневренные истребители не могут иметь очень эффективные, похожие на планеры крылья).  \n",
    "\n",
    "Однако здесь нас интересует, насколько все это можно было бы предположить просто из незатратного скринингового исследования, без понимания инженерной значимости задействованных переменных (что довольно часто имеет место в инженерном проектировании) и без возможности вычислить такой участок плитки (что почти всегда имеет место в инженерном проектировании – в конце концов, если бы целевая функция _f_ была настолько простой для вычисления, мы бы все равно не думали о суррогатном моделировании)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, что же показывает рисунок 1.2, изображающий результаты скринингового исследования при r = 5? Первое наблюдение, которое мы можем сделать, состоит в том, что существует четко определенная группа переменных, сгруппированных вокруг источника – напомним, что небольшая мера центральной тенденции(мат.ожидания???) является особенностью входных данных с небольшим влиянием на целевую функцию. Действительно, здесь мы видим, что вес краски, как и ожидалось, а также динамическое давление(скоростной напор??) имеют малую меру центральной тенденции. То же самое рассуждение применимо (и подтверждается таблицей 1.1) к коэффициенту конусности и развертке четверти хорды.  \n",
    "\n",
    "<!-- ![ssd_sm](img/ssd_sm.png){ width = 50% } -->\n",
    "<img src=\"img/ssd_sm.png\" alt=\"ssd_sm\" style=\"width:75%;\"/>\n",
    "\n",
    "__Рис. 1.2.__ Оценки средних и стандартных отклонений распределений элементарных воздействий каждой из 10 переменных веса крыла в данном примере."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотя среднее значение все еще близко к нулю, переменная с наибольшей центральной тенденцией в этой группе - это вес топлива $W_{fw}$. Его выборка элементарных воздействий имеет очень низкое стандартное отклонение и среднее значение немного больше, чем у остальной группы, что указывает на то, что он более важен, чем предыдущие параметры, но не участвует в межпеременных взаимодействиях. График показывает, что $A$ и $tc$ имеют одинаковую важность, а из-за высоких значений стандартного отклонения они имеют нелинейный/интерактивный эффект на целевую функцию.  \n",
    "\n",
    "Наконец, неудивительно, что большая центральная тенденция и большая мера разброса указывают на то, что $W_{dg}$, $S_w$ и $N_z$ оказывают наиболее значительное влияние на вес крыла. Конечно, авиаконструкторы знают, что общий вес самолета и площадь крыла должны быть сведены к минимуму (последнее обычно диктуется такими ограничениями, как требуемая скорость сваливания, посадочная дистанция, скорость разворота и т. д.) И что требование высокого коэффициента нагрузки $N_z$ приведет к необходимости использования прочных, тяжелых крыльев. На самом деле, именно поэтому мы использовали такую хорошо понятную функцию здесь, чтобы проиллюстрировать работу алгоритма скрининга.  \n",
    "\n",
    "Мы кратко вернемся к вопросу установления уровня важности (или активности) переменных целевой функции в разделе о моделях Кригинга. А теперь давайте рассмотрим следующий этап процесса моделирования. С помощью активных переменных, идентифицированных (либо с помощью инженерного суждения, либо с помощью систематического скринингового исследования), мы можем теперь спроектировать основной план осуществления выборки в проектном пространстве, определяемом этими переменными. Это послужит основой для данных, на которых будет строиться суррогатная модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разработка плана по осуществлению выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стратификация\n",
    "\n",
    "\n",
    "    Стратификация – это упорядочение объектов системы по уровням (стратам) с целью создания иерархического описания системы \n",
    "\n",
    "\n",
    "Общей особенностью всех аппроксимирующих моделей, рассмотренных в этой книге, является то, что они более точны вблизи точек, в которых мы оценивали целевую функцию. В последующих главах мы познакомимся с законами, определяющими зависимость правильности модели от расстояния до этих точек. Но на данный момент мы просто сделаем интуитивный вывод: для равномерного уровня точности модели необходимо равномерное распределение точек. Такой план выборки называют _заполняющим пространство_.  \n",
    "Самый простой метод такой выборки - это прямоугольная сетка точек. Это полный факториальный метод, т.е. он подвержен \"проклятию размерности\".  \n",
    "Вот упрощённая версия функции на Python, которая должна сгенерировать полный факториальный план выборки в единичном гиперкубе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullfactorial(q, Edges=1):\n",
    "    \"\"\"\n",
    "    Генерирует полный факториальный план выборки в единичном кубе\n",
    "    \n",
    "    Вход:\n",
    "        q - к-мерный вектор, содержащий число точек выборки вдоль\n",
    "            каждой оси гиперкуба\n",
    "        Edges - если Edges=1, то точки выборки будут браться на одинаковом\n",
    "                расстоянии от края до края,\n",
    "                иначе точки будут браться в центрах ячеек  n = q1*q2*...*qk,\n",
    "                заполняющих единичный гиперкуб.\n",
    "    Выход:\n",
    "        X - полный факториальный план выборки\n",
    "    \"\"\"\n",
    "    if np.min(q) < 2:\n",
    "        print(\"Error: в кажом измеренеии должно быть хотя бы две точки\")\n",
    "        print(f\"q = {q}\")\n",
    "        return\n",
    "\n",
    "    #Общее число точек в плане выборки\n",
    "    n = np.prod(q)\n",
    "    \n",
    "    #Число измерений гиперкуба\n",
    "    k = len(q)\n",
    "    \n",
    "    #Выделим место для будущего плана выборки\n",
    "    X = np.zeros((n, k))\n",
    "    \n",
    "    #Вспомогательный элемент\n",
    "    q = np.append(q, 1)\n",
    "    \n",
    "    for j in np.arange(k):\n",
    "        if Edges == 1:\n",
    "            one_d_slice = np.hstack((np.arange(0, 1, 1 / (q[j]-1)), 1))\n",
    "        else:\n",
    "            one_d_slice = np.hstack((np.array(1 / (2*q[j]), 1, 1 / q[j]),1))\n",
    "        \n",
    "        column = np.array([])\n",
    "        while len(column) < n:\n",
    "            for l in np.arange(q[j]):\n",
    "                column = np.concatenate([column, one_d_slice[l] * np.ones((np.prod(q[j+1:])))])\n",
    "        \n",
    "        X[:,j] = column\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Пример_ : рассмотрим обычный трёхмерный куб. Пусть (q1,q2,q3) = (3,4,5), тогда имеем следующие сетки по осям:\n",
    "    1. по первой: [0, 0.5, 1]\n",
    "    2. по второй: [0, 1/3, 2/3, 1]\n",
    "    3. по третей: [0, 1/4, 1/2, 3/4, 1]  \n",
    "    \n",
    "В итоге полный факториальный план выборки $X$ имеет вид:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.25      ],\n",
       "       [0.        , 0.        , 0.5       ],\n",
       "       [0.        , 0.        , 0.75      ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.33333333, 0.        ],\n",
       "       [0.        , 0.33333333, 0.25      ],\n",
       "       [0.        , 0.33333333, 0.5       ],\n",
       "       [0.        , 0.33333333, 0.75      ],\n",
       "       [0.        , 0.33333333, 1.        ],\n",
       "       [0.        , 0.66666667, 0.        ],\n",
       "       [0.        , 0.66666667, 0.25      ],\n",
       "       [0.        , 0.66666667, 0.5       ],\n",
       "       [0.        , 0.66666667, 0.75      ],\n",
       "       [0.        , 0.66666667, 1.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.25      ],\n",
       "       [0.        , 1.        , 0.5       ],\n",
       "       [0.        , 1.        , 0.75      ],\n",
       "       [0.        , 1.        , 1.        ],\n",
       "       [0.5       , 0.        , 0.        ],\n",
       "       [0.5       , 0.        , 0.25      ],\n",
       "       [0.5       , 0.        , 0.5       ],\n",
       "       [0.5       , 0.        , 0.75      ],\n",
       "       [0.5       , 0.        , 1.        ],\n",
       "       [0.5       , 0.33333333, 0.        ],\n",
       "       [0.5       , 0.33333333, 0.25      ],\n",
       "       [0.5       , 0.33333333, 0.5       ],\n",
       "       [0.5       , 0.33333333, 0.75      ],\n",
       "       [0.5       , 0.33333333, 1.        ],\n",
       "       [0.5       , 0.66666667, 0.        ],\n",
       "       [0.5       , 0.66666667, 0.25      ],\n",
       "       [0.5       , 0.66666667, 0.5       ],\n",
       "       [0.5       , 0.66666667, 0.75      ],\n",
       "       [0.5       , 0.66666667, 1.        ],\n",
       "       [0.5       , 1.        , 0.        ],\n",
       "       [0.5       , 1.        , 0.25      ],\n",
       "       [0.5       , 1.        , 0.5       ],\n",
       "       [0.5       , 1.        , 0.75      ],\n",
       "       [0.5       , 1.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.25      ],\n",
       "       [1.        , 0.        , 0.5       ],\n",
       "       [1.        , 0.        , 0.75      ],\n",
       "       [1.        , 0.        , 1.        ],\n",
       "       [1.        , 0.33333333, 0.        ],\n",
       "       [1.        , 0.33333333, 0.25      ],\n",
       "       [1.        , 0.33333333, 0.5       ],\n",
       "       [1.        , 0.33333333, 0.75      ],\n",
       "       [1.        , 0.33333333, 1.        ],\n",
       "       [1.        , 0.66666667, 0.        ],\n",
       "       [1.        , 0.66666667, 0.25      ],\n",
       "       [1.        , 0.66666667, 0.5       ],\n",
       "       [1.        , 0.66666667, 0.75      ],\n",
       "       [1.        , 0.66666667, 1.        ],\n",
       "       [1.        , 1.        , 0.        ],\n",
       "       [1.        , 1.        , 0.25      ],\n",
       "       [1.        , 1.        , 0.5       ],\n",
       "       [1.        , 1.        , 0.75      ],\n",
       "       [1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = np.array([3,4,5])\n",
    "X = fullfactorial(q)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fullfactorial](img/fullfactorial.bmp)  \n",
    "__Рис. 1.3.__ Пример трёхмерного полнофакториального плана выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что такая конструкция удовлетворяет критерию однородности. Но она имеет два существенных недостатка.\n",
    "Во-первых, такой план определён только для конструкций определённых размеров, которые могут быть записаны как произведение количеств точек вдоль каждой оси, т.е. $n = q_1 \\times q_2 \\times ... \\times q_k$.  \n",
    "Во-вторых, при проецировании на оси наборы точек будут перекрываться, и можно утверждать, что выборку для любой отдельной переменной можно улучшить, убедившись, что эти проекции являются как можно более однородными.  \n",
    "Это может быть сделано путем разбиения диапазона значений этой переменной на относительно большое число ячеек одинакового размера и генерации случайных подвыборок одинакового размера внутри этих ячеек. Этот подход известен как _стратифицированная случайная выборка_. Естественным развитием этой идеи является создание плана выборки, стратифицированного по всем его измерениям. Обычно используют метод _Латинской гиперкубической выборки_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Латинские квадраты и случайные Латинские гиперкубы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как уже было сказано, стратификация плана выборки направлена на создание точек, проекции которых на оси переменных однородны. Прежде чем мы рассмотрим общие методы построения таких планов, стоит рассмотреть случай дискретнозначных переменных в двух измерениях. Такие однородные проекционные планы могут быть сгенерированы довольно легко: если требуется $n$ ???точек измерения???, то квадрат $n \\times n$ строится путём заполнения каждого столбца и каждой строки некоторой перестановкий $\\{1,2,...,n\\}$, то есть каждое число должно только один раз появляться в каждом столбце и в каждой строке. Например, для $n=4$ _Латинский квадрат_ (так обычно называют такие планы выборки) имеет вид:  \n",
    "\n",
    "\n",
    "![LSQ](img/Latin_Square_n=4.bmp)  \n",
    "\n",
    "Мы выделили единички (__1__), чтобы проиллюстрировать идею равномерной проекции, но, конечно, мы могли бы выбрать 2, 3 или 4 с тем же успехом. Кроме того, это всего лишь один произвольно выбранный четырехточечный латинский квадрат – мы могли бы с равным успехом выбрать любой из других 575 возможных вариантов. Кстати, число различных латинских квадратов довольно резко возрастает с ростом n; например, существует 108 776 032 459 082 956 800 латинских квадратов восьмого порядка! (Доказательство данного факта предоставлено читателю в качестве упражнения.)\n",
    "\n",
    "Построение _Латинского гиперкуба_ (многомерного расширения Латинского квадрата) можно сделать аналагичным образом: разделить Область Проектирования на гиперкубы одинакового размера (ячейки) и поместить точки в эти ячейки (по одно точке в ячейку) таким образом, чтобы выполнялось следующее условие. Через каждую точку проведём линии, параллельные осям гиперкуба. Тогда каждая такая линия должна проходить ровно через одну точку. Выполнение данного условия проиллюстрировано на рис. 1.4. для трёхмерного куба  \n",
    "![LHC3D](img/LatinHiperCube3D.bmp)  \n",
    "__Рис. 1.4.__ Трёхпеременный десятиточечный план выборки с помощью Латинского гиперкуба. Показан в трёх измерениях(сверху слева) вместе с его двумерными проекциями. Все десять точек видны на каждой из проекций, и каждая строка и столбец ячеек содержит ровно одну точку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получаем такой план выборки следующим образом. Если $X$ - это матрица $n \\times k$, в которой мы хотим записать этот план (каждая строчка обозначает одну точку) то мы начинаем заполнение $X$ случайными перестановками $\\{1,2,...,n\\}$ в каждом столбце и нормализуем наш план в $k$-мерном кубе $[0,1]^k$. Далее представлена реализация этого алгоритма на Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rlh(n, k , Edges=0):\n",
    "    \"\"\"\n",
    "    Генерирует случайный k-переменный n-точечный план выборки \n",
    "    с помощью Латинского гиперкуба\n",
    "    \n",
    "    Вход:\n",
    "        n - желаемое количество точек\n",
    "        k - число проектных переменных (количество измерений)\n",
    "        Edges - если Edges=1, то крайние ячейки будут иметь свой центр \n",
    "                на краю области,\n",
    "                иначе ячейки будут полностью содержаться в области\n",
    "    Выход:\n",
    "        X - k-переменный n-точечный План выборки с помощью \n",
    "        Латинского гиперкуба\n",
    "    \"\"\"\n",
    "    \n",
    "    #Выделим место для будущего плана выборки\n",
    "    X = np.zeros((n, k))\n",
    "    \n",
    "    for i in np.arange(k):\n",
    "        X[:,i] = 1 + np.random.permutation(n)\n",
    "    if Edges==1:\n",
    "        X = (X - 1) / (n-1)\n",
    "    else:\n",
    "        X = (X - 0.5) / n\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2e2a291f588>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = rlh(4,2)\n",
    "plt.scatter(y[0][0], y[0][1])\n",
    "plt.scatter(y[1][0], y[1][1])\n",
    "plt.scatter(y[2][0], y[2][1])\n",
    "plt.scatter(y[3][0], y[3][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, приведенный выше метод даст рандомизированный план выборки, проекции которого на ось равномерно распределены (многомерная стратификация). Однако, это не гаратирует, что план будет _заполняющим пространство_ , потому что размещение всех точек на главной диагонали области проектирования будет отвечать критерию многомерной стратификации, но ,интуитивно, не будет заполнять имеющееся пространство равномерно.  \n",
    "Поэтому нам нужна некоторая мера равномерности, которая позволит нам различить \"хорошие\" и \"плохие\" Латинские гиперкубы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Латинские гиперкубы, _заполняющие пространство_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной из наиболее распространённых мер равномерности плана выборки является метрика ___максимума и минимума___ (___MaxMin___) (1990г, Джонсон и соавторы). Разъясним суть этой метрики.  \n",
    "Пусть $d_1, \\,d_2, ... d_m$ список уникальных значений расстояний между всеми возможными парами точек в плане выборки $X$, отсортированных в порядке возрастания. Далее, пусть $J_1, \\,J_2, ... J_m$ - это список таких чисел, что $J_j$ равно числу пар точек в $X$, расстояние между которыми равно $d_j$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Определение 1.1.__  \n",
    "Если выполнены следующие условия:\n",
    "1. среди всех возможных планов выборки $X$ имеет максимальное значение величины $d_1$\n",
    "2. при этом значение величины $J_1$ минимально,  \n",
    "\n",
    "тогда $X$ называется __максимально минимальным(максиминовым)__ планом выборки среди всех возможных планов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что это определение может быть применено к любому набору планов выборки, но мы ограничим нашу область исследования классом латинских гиперкубов из-за их хороших стратификационных свойств. Тем не менее, даже в этой более узкой области _Определение 1.1_ все ещё может дать несколько максиминовых конструкций. Поэтому мы будем использовать более полное __определение__, избавляющее от неоднозначности, __Морриса и Митчела__(1995).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Определение 1.2.__  \n",
    "План выборки $X$ называется __максимально минимальным(максиминовым)__ среди всех возможных планов, если он максимизирует $d_1$, и для всех планов, для которых это выполняется, минимизирует $J_1$, и для всех планов, для которых это выполняется максимизирует $d_2$ и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем двигаться дальше, нам нужно уточнить, что мы подразумеваем под \"расстоянием\" в приведенных выше определениях.  \n",
    "Наиболее широко используемой метрикой является _р-норма_ пространства:\n",
    "$$d_p(x^{(i_1)},x^{(i_2)}) = (\\sum\\limits_{j=1}^k |X_j^{(i_1)} - x_j^{(i_2)}|^p)^{1/p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае $p=1$ это _Манхэттоновское расстояние_ (или _прямоугольное_ ), а случае $p=2$ это _Евклидова норма_.  \n",
    "На сегодняшний день нельзя с уверенностью утверждать, что одна норма эффективнее других (без учёта исследуемой модели), хотя точно можно сказать, что прямоугольное расстояние значительно \"дешевле\" вычислять. Однако выбор нормы может быть весьма существенным, особенно если предстоит оценить большие планы выборки.  \n",
    "\n",
    "Перейдём к практическим аспектам Определения 1.2. Для начала, нужно построить вектора $d_1, \\,d_2, ... d_m$ и $J_1, \\,J_2, ... J_m$. Далее приведена реализация этой задачи на Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jd(X, p=1):\n",
    "    \"\"\"\n",
    "    Вычисляет расстояния между всеми парами точек в плане выборки X \n",
    "    с помощью p–нормы, сортирует их в порядке возрастания и \n",
    "    удаляет повторные вхождения.\n",
    "    \n",
    "    Вход:\n",
    "        X - исследуемый план выборки\n",
    "        p - используемая норма для вычисления расстояний\n",
    "    Выход:\n",
    "        J - массив количеств пар точек, разделенных каждым \n",
    "            значением расстояния\n",
    "        distinct_d - список различных значений расстояния\n",
    "    \"\"\"\n",
    "    \n",
    "    #Число точек в плане выборки = числу строк в X\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    #Вычисление расстояний между всеми парами точек\n",
    "    d = np.zeros(n*(n-1)//2)\n",
    "    \n",
    "    for i in np.arange(n-1):\n",
    "        for j in np.arange(i+1, n):\n",
    "            d[i*n - i*(i+1)//2 + j-i-1] = np.linalg.norm(X[i,:] - X[j,:], p)\n",
    "            \n",
    "    #Удаление повторящихся значение и сортировка по возрастанию\n",
    "    distinct_d = np.unique(d)\n",
    "    \n",
    "    #Выделим память для J\n",
    "    J = np.zeros(len(distinct_d))\n",
    "    \n",
    "    #Заполняем J\n",
    "    for i in range(len(J)):\n",
    "        #J[i] будет содержать число пар точек с расстоянием \n",
    "        #distinct_d[i] между ними\n",
    "        J[i] = np.sum(np.isin(d,distinct_d[i]))\n",
    "    \n",
    "    return J, distinct_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([48., 30., 15., 76., 48., 24., 15., 15., 88., 76., 38., 24., 24.,\n",
       "        95., 88., 44., 38., 38., 88., 80., 40., 44., 44., 78., 64., 32.,\n",
       "        40., 40., 60., 40., 20., 32., 32., 48., 16.,  8., 20., 20., 32.,\n",
       "         8.,  4.,  8.,  8., 20.,  4.,  4.,  8.,  4.]),\n",
       " array([0.25      , 0.33333333, 0.33333333, 0.5       , 0.58333333,\n",
       "        0.58333333, 0.66666667, 0.66666667, 0.75      , 0.83333333,\n",
       "        0.83333333, 0.91666667, 0.91666667, 1.        , 1.08333333,\n",
       "        1.08333333, 1.16666667, 1.16666667, 1.25      , 1.33333333,\n",
       "        1.33333333, 1.41666667, 1.41666667, 1.5       , 1.58333333,\n",
       "        1.58333333, 1.66666667, 1.66666667, 1.75      , 1.83333333,\n",
       "        1.83333333, 1.91666667, 1.91666667, 2.        , 2.08333333,\n",
       "        2.08333333, 2.16666667, 2.16666667, 2.25      , 2.33333333,\n",
       "        2.33333333, 2.41666667, 2.41666667, 2.5       , 2.66666667,\n",
       "        2.66666667, 2.75      , 3.        ]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J,d = jd(X)\n",
    "J,d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень трудоемкой частью этого расчета является создание вектора, содержащего расстояния между всеми возможными парами точек $d$. Это становится особенно важным для больших планов выборки (например, в случае плана из 1000 точек ($n=1000$) требуется почти полмиллиона вычислений). Поэтому предварительное выделение памяти имеет важное значение: данный алгоритм будет исполняться быстрее в отличие от алгоритма, где к $d$ добавляется каждый новый элемент, что потребовало бы использования дорогостоящего динамического выделения памяти.  \n",
    "\n",
    "Теперь нам нужно реализовать само Определение 1.2. Поскольку поиск латинского гиперкуба, наиболее заполняющего пространство, потребует попарных сравнений, то мы будем \"разделять и властвовать\": упростим проблему до задачи выбора лучшего из двух планов выборки. Функция ___mm(X1,X2,p)___ выполит это, вернув индекс (\"1\" или \"2\") более подходящего плана или 0, если они равны (третий аргумент функции p - это норма, используемая для вычисления расстояний):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm(X1, X2, p=1):\n",
    "    \"\"\"\n",
    "    По двум данным планам выборки выбирает тот, который лучше \n",
    "    заполняет пространство по критерию Морриса-Митчела\n",
    "    \n",
    "    Вход:\n",
    "        X1,X2 - два плана выборки;\n",
    "        p - используемая норма для вычисления расстояний\n",
    "    Выход:\n",
    "        Mmplan - если Mmplan = 0, то планы выборки либо одинаковы, \n",
    "                 либо одинаково заполняют пространство,\n",
    "                 если Mmplan = 1, то X1 лучше заполняет пространство,\n",
    "                 если Mmplan = 2, то X2 лучше заполняет пространство. \n",
    "    \"\"\"\n",
    "    \n",
    "    #проверим матрицы на содержание одинаковых точек (строк)\n",
    "    def eq_rows(m1, m2):\n",
    "        n = m1.shape[0]\n",
    "        for i in np.arange(n):\n",
    "            w = np.where(np.prod([m1[j,:] for j in range(n-i)] == m2[i,:],axis=1))\n",
    "            if len(w[0]) == 0:\n",
    "                return False\n",
    "            row = w[0][0]\n",
    "            m1 = np.delete(m1, row, axis=0)\n",
    "        return True\n",
    "    if eq_rows(X1, X2):\n",
    "        Mmplan = 0\n",
    "        return Mmplan\n",
    "    \n",
    "    #Из данных планов вычисляем расстояния и пары точек\n",
    "    J1, d1 = jd(X1,p); m1 = len(d1)\n",
    "    J2, d2 = jd(X2,p); m2 = len(d2)\n",
    "    \n",
    "    #Смешаем массивы J и d. Заметьте!!!, что согласно Определению 1.2\n",
    "    #мы максимизируем d и минимизируем J\n",
    "    V1 = []\n",
    "    for i in range(m1):\n",
    "        V1.append(d1[i])\n",
    "        V1.append(-J1[i])\n",
    "    V1 = np.array(V1)\n",
    "    \n",
    "    V2 = []\n",
    "    for i in range(m2):\n",
    "        V2.append(d2[i])\n",
    "        V2.append(-J2[i])\n",
    "    V2 = np.array(V2)\n",
    "    \n",
    "    #Более длинный вектор можно обрезать до длины более короткого\n",
    "    m = np.min([m1,m2])\n",
    "    V1 = V1[:m]\n",
    "    V2 = V2[:m]\n",
    "    \n",
    "    #Сгенерируем вектор c[] таким образом, \n",
    "    #что c(i) = 1, если V1(i) > V2(i), и \n",
    "    #c(i) = 2, если V1(i) < V2(i), и c(i) = 0 в противном случае\n",
    "    c = (V1>V2) + 2*(V1<V2)\n",
    "    \n",
    "    #Если планы выборок неодинаковы, но одинаково заполняют \n",
    "    #пространство, то нужно вернуть ноль\n",
    "    if np.sum(c) == 0:\n",
    "        Mmplan = 0\n",
    "        return Mmplan\n",
    "    \n",
    "    #Тогда более подходящая конструкция (mmplan) соответствует\n",
    "    #первыму ненулевыму элементу c[]\n",
    "    i = 0\n",
    "    while c[i] == 0:\n",
    "        i += 1\n",
    "    Mmplan = c[i]\n",
    "    return Mmplan    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже говорили выше, поиск латинского гиперкуба, наиболее заполняющего пространство, потребует попарных сравнений. Поэтому теоретически мы могли бы написать алгоритм использующий функцию _mm_ качестве сравнителя. Однако есть некоторые экспериментальные данные (получены Морисом и Митчелом в 1995), показывающие, что результ не будет столь хорошим, как ожидалось...  \n",
    "Причина в том, что процесс сравнения остановится, как только мы найдем ненулевой элемент в массиве сравнения _c_ , и поэтому остальные значения в $d_1, \\,d_2, ... d_m$ и $J_1, \\,J_2, ... J_m$ будут потеряны. Они, однако, могли бы обеспечить процесс оптимизации потенциально полезной информацией.  \n",
    "Моррис и Митчелл (1995) определили следующую скалярную функцию, являющеюся критерием качества планов выборки (другими словами, эта функция вычисляет, как хорошо данный план выборки заполняет пространство). Она основана на логике Определения 1.2 и использует векторы $d_1, \\,d_2, ... d_m$ и $J_1, \\,J_2, ... J_m$ полностью:  \n",
    "$$ \\Phi_q(X) = (\\sum\\limits_{j=1}^m J_j d_j^{-q} )^{\\frac{1}{q}} $$\n",
    "\n",
    "Таким образом, чем меньше величина $\\Phi_q$, тем лучше $X$ заполняет пространство. Ниже представлена реализация данной формулы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmphi(X, q=2, p=1):\n",
    "    \"\"\"\n",
    "    Вычисляет значение критерия качества плана выборки \n",
    "    по формуле Морриса и Митчела.\n",
    "    \n",
    "    Вход:\n",
    "        X - план выборки\n",
    "        q - показатель степени, используемый при вычислении критерия\n",
    "        p - используемая норма для вычисления расстояний\n",
    "    Выход:\n",
    "        Phiq - значение критерия качества плана выбокри\n",
    "    \"\"\"\n",
    "    \n",
    "    # Посчитаем расстояние между всеми парами точек \n",
    "    # (с использованием p-нормы) и построим соответствующий массив J\n",
    "    J, d = jd(X,p)\n",
    "    Phiq = (np.sum( J*(d**(-q)) ))**(1/q)\n",
    "    return Phiq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта формула преобразует громоздкое определение критерия максимина в довольно аккуратную и компактную форму, но встаёт вопрос о том, как выбрать значение _q_. Большие _q_ гарантируют, что каждый член делает бОльший вклад в сумму, чем все последующие слогаемые. Таким образом, поскольку расстояния  $d_j$ расположены в порядке возрастания, то $\\Phi_q$ будет ранжировать планы выборки таким образом, чтобы они достаточно точно соответствовали исходному определению критерия. Более низкие значения _q_ задают критерий, который, хотя и не может точно соответствовать определению, но лучше поддается оптимизации.  \n",
    "\n",
    "Чтобы проиллюстрировать связь между Уравением (7) и критерием максимина в Определении 1.2, рассмотрим множества из 50 случайных Латинских гиперкубов разных размеров и размерностей. Затем упорядочим эти кубы внутри каждого множества согласно Определению 1.2, а также согласно значению функции $\\Phi_q$ (в каждом случае используем норму $p=1$). Проделаем эту операцию для ряда значений _q_.  \n",
    "\n",
    "![Phiq](img/fig-1-5.png)  \n",
    "    __Рис. 1.5.__ Графики, демонстрирующие разницу между максиминовым ранжированием и ранжированием по $\\Phi_q$ при разных значениях _q_ для наборов из 50 случайных Латинских гиперкубов разных размеров и размерностей (при использовании нормы p=1 при вычислении расстояний): по одной оси кубы отсортированы по определению максимина, а по другой - по значению $\\Phi_q$. Здесь _n_ - количество точек(размер плана выборки), _k_ - количество переменных(размерность плана выборки).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На рис. 1.5 представлены результаты этого небольшого исследования. Неразумно делать далеко идущие выводы только из нескольких произвольно выбранных экспериментов (да мы и не пытаемся). Тем не менее, корреляционные графики показывают, что чем больше план выборки, тем меньшее _q_ требуется для получения ранжирования на основе $\\Phi_q$, которое почти точно соответствует Определению 1.2. Если взять набор из 50 100-точечных 15-переменных гиперкубов, то нижний правый график рисунка 1.5 показывает, что ранжирование на основе $\\Phi_{250}$ отличается от определения только в трёх местах, при этом в ранжировании допущена только одна ошибка. На другом конце рисунка видно, что для $q = 1$ корреляция практически отсутствует, за исключением самых маленьких из рассмотренных планов выборки.  \n",
    "\n",
    "Если читатель пожелает провести собственное исследование для различных семейств планов выборки, то вот инструменты, необходимые для этого. Ранжирование по _mm_ и _mmphi_ с использованием простого алгоритма пузырьковой сортировки реализовано в mmsort и phisort соответственно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmsort(X3D, p=1):\n",
    "    \"\"\"\n",
    "    Ранжирует планы выборки в соответствии с определением \n",
    "    критерия Морриса–Митчелла. Примечание: аналогично алгоритму \n",
    "    phisort, который использует числовой критерий Phi_q \n",
    "    в качестве основы для ранжирования. \n",
    "    \n",
    "    Вход:\n",
    "        X3D-трёхмерный массив, содержащий планы выборки \n",
    "            для ранжирования: первая координата - номер плана выборки,\n",
    "            следующие две - двумерный план выборки X(см. ранее)\n",
    "        p - используемая норма для вычисления расстояний\n",
    "    Выход:\n",
    "        Index - массив индексов, содержащий ранжирование X3D\n",
    "    \"\"\"\n",
    "    \n",
    "    # Выделим память\n",
    "    Index = np.arange(len(X3D))\n",
    "    \n",
    "    # Сортировка пузырьком (с оптимизацией - swap-flag)\n",
    "    swap_flag = 1\n",
    "    \n",
    "    while swap_flag == 1:\n",
    "        swap_flag = 0\n",
    "        i = 0\n",
    "        while i < len(Index)-1:\n",
    "            if mm(X3D[Index[i]], X3D[Index[i+1]], p) == 2:  #то есть если второй план лучше первого\n",
    "                Index[i],Index[i+1] = Index[i+1], Index[i]\n",
    "                swap_flag = 1\n",
    "            i += 1\n",
    "    return Index\n",
    "\n",
    "\n",
    "def phisort(X3D, q=2, p=1):\n",
    "    \"\"\"\n",
    "    Ранжирует планы выборки в соответствии со значением функции Фq.\n",
    "    Вход:\n",
    "        X3D-трёхмерный массив, содержащий планы выборки \n",
    "            для ранжирования: первая координата - номер плана выборки,\n",
    "            следующие две - двумерный план выборки X(см. ранее)\n",
    "        q - показатель степени, используемый при вычислении критерия\n",
    "        p - используемая норма для вычисления расстояний\n",
    "    Выход:\n",
    "        Index - массив индексов, содержащий ранжирование X3D\n",
    "    \"\"\"\n",
    "    \n",
    "    # Выделим память\n",
    "    Index = np.arange(len(X3D))\n",
    "    \n",
    "    # Сортировка пузырьком (с оптимизацией - swap-flag)\n",
    "    swap_flag = 1\n",
    "    \n",
    "    while swap_flag == 1:\n",
    "        swap_flag = 0\n",
    "        i = 0\n",
    "        while i < len(Index)-1:\n",
    "            if mmphi(X3D[Index[i]],q,p) > mmphi(X3D[Index[i+1]],q,p):  #то есть если второй план лучше первого\n",
    "                Index[i],Index[i+1] = Index[i+1], Index[i]\n",
    "                swap_flag = 1\n",
    "            i += 1\n",
    "    return Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как же найти лучший латинский гиперкуб для конкретной задачи? Моррис и Митчелл (1995) рекомендуют минимизировать значение $\\Phi_q$ для $q = 1,2,5,10,20, 50$ и $100$ (рис.1.5 подтверждает, что это разумные значения), а затем выбрать лучший из полученных планов в соответствии с определением максимина. Тогда остается только один вопрос: как найти эти оптимизировать $\\Phi_q$? Мы обсудим это дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оптимизация $\\Phi_q$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы создали критерий(метрику), который позволяет нам определить, как хорошо данный латинский гиперкуб заполняет пространство. Теперь нам нужно оптимизировать эту метрику в пространстве латинских гиперкубов. Это ___не___ тривиальная задача – читатель вспомнит из более раннего обсуждения латинских квадратов, что это пространство огромно. Действительно, оно настолько обширно, что нам кажется маловероятным найти универсальное оптимальное решение для многих практических задач. Отсюда возникает другая задача: при заданном ограничении по времени найти наилучший возможный план выборки.  \n",
    "\n",
    "Это временное ограничение зависит от вычислительных затрат на получение значения целевой функции. Оптимальное разделение общих вычислительных усилий между созданием плана выборки и фактическим вычислением значений целевой функции является открытым исследовательским вопросом, хотя обычно на первую задачу редко выделяют более 5% общего времени работы.  \n",
    "\n",
    "Можно провести параллели с выбором того, _сколько времени_ потратить на _составление_ расписания для _повторения_ материала перед экзаменом. Хорошее расписание сделает повторение более эффективным, но никто не хочет тратить слишком много времени на само повторение!  \n",
    "\n",
    "Одна из проблем разработки оптимизатора плана выборки состоит в том, что нужно убедиться, что процесс поиска всегда остается в пространстве латинских гиперкубов. Мы видели, что определяющей особенностью латинского гиперкуба $X$ является то, что каждый столбец является перестановкой списка возможных уровней соответствующей переменной. Поэтому самое малое изменение, которое мы можем внести в латинский гиперкуб, не нарушая его ключевого свойства многомерной стратификации, - это поменять местами два элемента в любом из столбцов $X$. Вот Python-реализация такого преобразования (\"мутации\") латинского гиперкуба, обобщенная на случайные изменения, применяемые к нескольким сторонам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(X, PertNum=1):\n",
    "    \"\"\"\n",
    "    Меняет местами пары случайно выбранных элементов в случайно выбранных\n",
    "    столбцах плана выборки несколько раз. Если план выборки представляет \n",
    "    собой латинский гиперкуб, то результатом этой операции также будет\n",
    "    латинский гиперкуб.\n",
    "    Вход:\n",
    "        X - план выборки\n",
    "        PertNum-число изменений (возмущений), \n",
    "                которые должны быть внесены в X.\n",
    "    Выход:\n",
    "        X - возмущённый план выборки\n",
    "    \"\"\"\n",
    "    \n",
    "    n, k = X.shape\n",
    "    \n",
    "    for pert_count in np.arange(PertNum):\n",
    "        col = np.int64(np.floor(np.random.rand()*k))\n",
    "        \n",
    "        # Выбор двух различных случайных точек\n",
    "        el1, el2 = 1, 1\n",
    "        while el1 == el2:\n",
    "            el1 = np.int64(np.floor(np.random.rand()*n))\n",
    "            el2 = np.int64(np.floor(np.random.rand()*n))\n",
    "        \n",
    "        # Меняем местами два выбранных элемента\n",
    "        X[el1, col], X[el2,col] = X[el2,col], X[el1,col]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы используем термин \"мутация\", потому что эта задача поддается вычислениям, описываемым естественно-научными терминами. Моррис и Митчелл (1995) используют _алгоритм имитации отжига_ (simulated annealing, SA), подробный псевдокод которого можно найти в их работе. В качестве альтернативы здесь мы предлагаем метод, основанный на _эволюционном планировании_ (evolutionary operation, EVOP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Эволюционное планирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эволюционное планирование было разработано Джорджом Боксом в 1957 году для оптимизации химических процессов. Работало оно следующим образом. Текущие параметры реакции записывались в ячейку в центре доски, а ячейки-\"потомки\", содержащие значения параметров, слегка измененных по отношению к центральному (\"родительскому\") значению, располагались по краям. Как только реакция завершалась, для всех наборов переменных и соответсвующих полей записывались новые значения, а содержимое центральной ячейки будет заменялось содержимым установки с наибольшим выходом, и это становилось \"родителем\" нового набора периферийных ячеек.  \n",
    "Обычно это  рассматривается как локальная процедура поиска, хотя это зависит от размера шага мутации, то есть от числа различий между \"родительской\" ячейкой и её \"потомством\". Чем больше эти шаги, тем глобальнее область поиска.  \n",
    "Чтобы найти латинский гиперкуб, мы применяем стратегию _переменной области(variable scope strategy)_ . Мы начинаем с большой длины шага (то есть с относительно большого количества перестановок внутри столбцов) и, по мере продвижения, постепенно приближаемся к текущему наилучшему узлу притяжения(_аттрактору_), сокращая длину шага до одной перестановки.  \n",
    "На каждом этапе мы меняем(подвергаем мутации) (случайным образом, используя функцию ___perturb___) родителя _pertnum_  раз. Затем мы выбираем план выборки, который дает наименьшее значение $\\Phi_q$ (согласно критерию Морриса–Митчелла, рассчитанному в функции ___mmphi___) среди всех потомков _и_ родителей; на языке эволюционных вычислений эта философия отбора называется __элитизмом__. Если читатель хочет выбрать неэлитичный подход (например, склоняясь к более глобальному поиску), то код для EVOP может быть довольно легко изменён, чтобы исключить родителя из шага выбора.\n",
    "Таким образом, поиск заполняющих пространство латинских гиперкубов на основе EVOP - это действительно эволюционный процесс: наилучший план выборки является результатом неслучайного выживания случайных вариаций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подведём итог (Putting it all together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть все части задачи о поиске оптимального плана выборки: генератор случайных гиперкубов в качестве отправной точки для процесса оптимизации, метрика \"заполняемости пространства\", которую нам нужно оптимизировать, механизм оптимизации, который выполняет эту задачу, и функция сравнения, которая выбирает лучшие из оптимумов, найденных для различных значений $q$. Нам просто нужно выстроить все это в определенную последовательность. Вот воплощение решения этой задачи на Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestlh(n, k , Population, Iterations):\n",
    "    \"\"\"\n",
    "    Генерирует наилучший латинский гиперкуб путём оптимизации критерия \n",
    "    Морриса–Митчелла для диапазона показателей \n",
    "    и строит первые два измерения текущего гиперкуба на протяжении \n",
    "    всего процесса оптимизации\n",
    "    \n",
    "    Вход:\n",
    "        n - необходимое число точек\n",
    "        k - число проектных переменных\n",
    "        Population - число \"особей\" в оптимизаторе\n",
    "                     эволюционного планиования\n",
    "        Iterations - количество поколений, для которых \n",
    "                     выполняется оптимизатор эволюционного \n",
    "                     планирования\n",
    "        Замечание:  высокие значения величин Population и Iterations\n",
    "                    обеспечат высокое качество гиперкубов, \n",
    "                    но их поиск займет больше времени.\n",
    "   Выход:\n",
    "       X - Наилучший латинский гиперкуб\n",
    "   \"\"\"\n",
    "    \n",
    "    if k < 2:\n",
    "        print(\"Для k<2 Латинский гиперкуб не определен\")\n",
    "        return\n",
    "    \n",
    "    # Список значений q для оптимизации Phi_q\n",
    "    q = np.array([1,2,5,10,20,100])\n",
    "    \n",
    "    # Установим прямоугольную нормму расстояния для более быстрого\n",
    "    # поиска. Но если потребуется Евклидова норма, можно изменить на p=2\n",
    "    p = 1\n",
    "    \n",
    "    # Начнём со случайного Латинского Гиперкуба\n",
    "    Xstart = rlh(n,k)\n",
    "    X3D = np.empty((len(q),n,k))\n",
    "    \n",
    "    # для кажого q оптимизируем Phi_q\n",
    "    for i in np.arange(len(q)):\n",
    "        print(f\"Сейчас оптимизируется для q = {q[i]}\")\n",
    "        X3D[i][:][:] = mmlhs(XStart, Population, Iterations, q[i])\n",
    "    \n",
    "    # Сортировка по критерию Морриса–Митчелла\n",
    "    Index = mmsort(X3D, p)\n",
    "    print(f\"Лучший ГК соответствует q = {q[Index[0]]}\")\n",
    "    \n",
    "    # А вот собственно и сам Латинский Гиперкуб, заполняющий\n",
    "    # пространство лучше всего.\n",
    "    X = X3D[Index[0]]\n",
    "    \n",
    "    # Нарисуем проекции первых двух измерения\n",
    "    y = np.transpose(X)\n",
    "    plt.plot(y[0],y[1])\n",
    "    \n",
    "    plt.title(\"sometitle\", size=16)\n",
    "    plt.xlabel(\"x_1\", size=16)\n",
    "    plt.ylabel(\"x_2\", size=16)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!!!В коде используется не объявленая и не определённая функция MMLHS!!!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"!!!В коде используется не объявленая и не определённая функция MMLHS!!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит отметить, что нам не обязательно сортировать все планы-кандидаты в порядке возрастания – в конце концов, нам нужен только лучший из них. Тем не менее, добавленная вычислительная сложность минимальна (вектор всегда будет содержать столько элементов, сколько существует возможных значений $q$, и сортируется только индексный массив, а не фактическое хранилище планов), и это дает читателю возможность сравнить, при желании, планы выборок, к которым приводят различные значения $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подмножества, заполняющие пространство"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До сих пор мы рассматривали проблему минимизации $\\Phi_q$ в пространстве всех латинских гиперкубов определенного размера _n_ и размерности _k_. Другой вопрос может заключаться в следующем: как найти наилучший план заполнения пространства в более ограниченном пространстве, скажем, в подмножестве $X_s$ из $n_s$ элементов плана $X$ из _n_ элементов? Это не просто учебная задача, поскольку эта проблема возникнет позже, когда мы будем обсуждать улучшение качества предиктора путём пробега заполняющего пространство подмножества по его обучающим данных с применением анализа более высокой точности.  \n",
    "Поскольку выбор подмножества из $n_s$ элементов, минимизирующего $\\Phi_q$, является NP-полной задачей(то есть для неё пока не найден полиномиальный алгоритм решения), то исчерпывающий поиск должен был бы исследовать $C^{n}_{n_s} = \\frac{n_s!}{n!(n_s - n)!}$ подмножеств (неосуществимая задача для любых мощностей). Альтернативной стратегией может быть следующий жадный алгоритм, направленный на поиск хотя бы локального оптимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стратегия №1: жадный алгоритм локального поиска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с набора точек $x^{(i)}, \\, i \\leq n$, в качестве первой строки в  $X_s$, затем мы перебираем оставшихся кандидатов $x^{(j)}, \\, j = 1, ...,i-1,i+1, ..., n$ и добавляем точку, которая минимизирует критерий Морриса–Митчелла. Затем этот цикл повторяется (исключая из рассмотрения точки, которые мы уже включили), выбирая каждый раз точку, которая при добавлении к $X_s$ минимизирует критерий оптимальности с учётом уже имеющихся точек. Это сродни локальной оптимизации цитериона – лучших результатов можно добиться если повторить процесс, начиная со всех возможных $n_s$ стартовых точек, сохраняя лучшие $X_s$ в целом (мультистартный локальный поиск).  \n",
    "Заметим, что этот подход и не является исчерпывающим, и он может оказаться вычислительно затратным для планов, размер которых превышает несколько десятков элементов. Рассмотрим другую, более дешёвую альтернативу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Стратегия №2: Перестановочный алгоритм (exchange algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы начинаем со случайно выбранного подмножества $X_s$ и вычисляем для него значения критерия  $\\Phi_q$. Затем мы переставляем первую точку $x^{(1)}_s$ с каждой из оставшихся точек в $X \\setminus X_s$ и сохраняем перестановку, которая даёт наилучшее значение $\\Phi_q$. Вот реализация этого метода на Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(X, ns):\n",
    "    \"\"\"\n",
    "    По заданному плану выборки возвращает подмножество заданного \n",
    "    размера с оптимизированными свойствами заполнения пространства \n",
    "    (в соответствии с критерием Морриса–Митчелла).\n",
    "    \n",
    "    Вход:\n",
    "        X - полный план выборки\n",
    "        ns- желаемый размер подмножества\n",
    "    Выход:\n",
    "        Xs - подмножество с оптимизированными свойствами \n",
    "             заполнения пространства\n",
    "        Xr - остаток разности X\\Xs\n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # Норма и метрика для Фq. При необходимости можно изменить.\n",
    "    p, q = 1, 5\n",
    "    \n",
    "    # Случайная перестановка номеров строк\n",
    "    r = np.random.permutation(n)\n",
    "    \n",
    "    Xs = X[r[:ns],:]\n",
    "    Xr = X[r[ns:],:]    \n",
    "    \n",
    "    for j in np.arange(ns):\n",
    "        orig_crit = mmphi(Xs,q,p)\n",
    "        orig_point = np.array(Xs[j,:])\n",
    "        \n",
    "        # Ищем лучшую точку для замены текущей\n",
    "        bestsub = 0\n",
    "        bestsubcrit = np.inf\n",
    "        \n",
    "        for i in np.arange(n-ns):\n",
    "            # Мы заменяем текущую, j-ю точку каждой из \n",
    "            # оставшихся точек последовательно\n",
    "            Xs[j,:] = Xr[i,:] \n",
    "            crit = mmphi(Xs,q,p)\n",
    "            \n",
    "            if crit < bestsubcrit:\n",
    "                bestsubcrit = crit\n",
    "                bestsub = i\n",
    "        \n",
    "        if bestsubcrit < orig_crit:\n",
    "            Xs[j,:] = Xr[bestsub,:]\n",
    "            Xr[bestsub,:] = orig_point\n",
    "        else:\n",
    "            Xs[j,:] = orig_point    \n",
    "    \n",
    "    return Xs, Xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.        , 0.        ],\n",
       "        [1.        , 1.        , 0.        ],\n",
       "        [1.        , 0.        , 0.25      ],\n",
       "        [0.5       , 0.66666667, 0.        ],\n",
       "        [0.5       , 1.        , 1.        ],\n",
       "        [0.        , 0.        , 0.75      ],\n",
       "        [0.        , 0.66666667, 1.        ],\n",
       "        [0.        , 1.        , 0.25      ],\n",
       "        [0.5       , 0.33333333, 0.5       ],\n",
       "        [1.        , 0.33333333, 1.        ]]),\n",
       " array([[0.        , 1.        , 1.        ],\n",
       "        [0.        , 0.33333333, 0.        ],\n",
       "        [0.5       , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.25      ],\n",
       "        [1.        , 0.66666667, 1.        ],\n",
       "        [1.        , 1.        , 0.5       ],\n",
       "        [1.        , 0.66666667, 0.        ],\n",
       "        [1.        , 0.66666667, 0.25      ],\n",
       "        [1.        , 0.        , 1.        ],\n",
       "        [0.        , 1.        , 0.75      ],\n",
       "        [0.5       , 0.        , 1.        ],\n",
       "        [1.        , 0.33333333, 0.25      ],\n",
       "        [0.5       , 1.        , 0.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [0.        , 1.        , 0.        ],\n",
       "        [0.        , 0.33333333, 0.25      ],\n",
       "        [0.5       , 0.        , 0.5       ],\n",
       "        [1.        , 1.        , 0.75      ],\n",
       "        [0.5       , 0.33333333, 0.25      ],\n",
       "        [0.        , 0.33333333, 0.75      ],\n",
       "        [0.        , 0.66666667, 0.75      ],\n",
       "        [0.5       , 0.66666667, 1.        ],\n",
       "        [1.        , 0.33333333, 0.        ],\n",
       "        [0.        , 0.66666667, 0.25      ],\n",
       "        [1.        , 0.        , 0.        ],\n",
       "        [0.5       , 1.        , 0.75      ],\n",
       "        [0.5       , 0.33333333, 0.75      ],\n",
       "        [0.        , 1.        , 0.5       ],\n",
       "        [0.        , 0.33333333, 0.5       ],\n",
       "        [0.5       , 0.33333333, 1.        ],\n",
       "        [0.5       , 0.        , 0.75      ],\n",
       "        [1.        , 0.66666667, 0.5       ],\n",
       "        [0.5       , 0.        , 0.25      ],\n",
       "        [0.5       , 1.        , 0.5       ],\n",
       "        [1.        , 0.33333333, 0.5       ],\n",
       "        [0.5       , 0.66666667, 0.75      ],\n",
       "        [0.        , 0.        , 0.5       ],\n",
       "        [0.5       , 0.33333333, 0.        ],\n",
       "        [1.        , 0.        , 0.75      ],\n",
       "        [0.5       , 1.        , 0.25      ],\n",
       "        [0.        , 0.33333333, 1.        ],\n",
       "        [0.5       , 0.66666667, 0.5       ],\n",
       "        [0.        , 0.66666667, 0.        ],\n",
       "        [1.        , 1.        , 0.25      ],\n",
       "        [1.        , 0.66666667, 0.75      ],\n",
       "        [1.        , 0.33333333, 0.75      ],\n",
       "        [0.        , 0.        , 1.        ],\n",
       "        [0.5       , 0.66666667, 0.25      ],\n",
       "        [0.        , 0.66666667, 0.5       ],\n",
       "        [1.        , 0.        , 0.5       ]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset(X,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Замечание о гармонических откликах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы завершаем наше обсуждение планов выборки.\n",
    "\n",
    "Если предполагается, что исследуемая функция (для которой мы и формировали план выборки) имеет гармоническую составляющую с длиной волны, равной $\\frac{k}{n}, k \\in \\mathbb{Z}$ (т.е. длина волны кратна ширине одного _бина_ в латинском гиперкубе), то полностью однородные проекционные свойства латинского гиперкуба (или полный факториальный план выборки) могут привести к вводящим в заблуждение выборкам (они всегда берут выборку сигнала в одной и той же фазе, поэтому будет казаться, что исследуемая функция - константа). Этой потенциальной (хотя и маловероятной) ловушки можно избежать, добавив небольшое случайное возмущение в каждую точку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим случайное возмущение\n",
    "# (Для случая, когда возможно присутствие гармонической составляющей)\n",
    "some_condition = True\n",
    "if some_condition:\n",
    "    n, k = X.shape\n",
    "    X = X + (np.random.random((n,k)) - 0.5)*(1/n)*0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Указания для дальнейшего чтения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "О Важности разработки плана выборки говорится во множестве научных книг(хотя не во всех этих работах используется та же терминология, что и здесь). Наше практическое знакомство с предметом ограничено небольшим подмножеством множества появившихся методов, и оно неизбежно подвержено, в некоторой степени, личному предубеждению автора. Однако, что более важно, мы выделили самые общие подходы, т.е. те, которые делают самые слабые предположения типе и параметрах задачи.  \n",
    "Мы также ограничили описание теоретических основ рассматриваемых методов тем, что считали необходимым для их правильного использования. Вот несколько дополнительных источников, с которыми читатель, возможно, пожелает ознакомиться.  \n",
    "\n",
    "История латинских гиперкубов началась в 1979 году с технометрической работы Маккея и др(1979). Затем последовал ряд уточнений, включая применение критериев _межсайтового_ расстояния к планам латинских гиперкубов. Из них мы сосредоточились здесь на критерии максимина. Работа Сантнера и др. (2003) является хорошим источником информации о других критериях.  \n",
    "\n",
    "Другим классом планов выборки, вызвавшим определенный интерес в последние десятилетия, являются _ортогональные массивы_. Матрица $X(n × k)$ с элементами из набора символов s ≥ 2 называется __ортогональным массивом силы $r$__, размера $n$ с ограничениями $k$ и уровнями $s$, если каждая подматрица $X(n × r)$  содержит все возможные векторы строк $1 × r$ с одинаковой частотой $\\lambda$ (обратите внимание на довольно неудобное ограничение, что число элементов должно быть $n = \\lambda s^r$). В статье 1993 года Танг (1993) вводит ортогональные массивы на основе латинских гиперкубов. Они существенно расширяют одномерные стратификационные свойства латинских гиперкубов до r-вариационных полей, опять же для ограниченного диапазона размеров плана.\n",
    "\n",
    "Планы выборки, рассмотренные в этой главе, обычно  были основаны на предположении, что размер  $n$ плана предопределен. Это не всегда так, поскольку, хотя мы можем знать, на какое общее вычислительное время мы можем рассчитывать, не всегда очевидно, сколько планов-кандидатов мы сможем оценить за это время (некоторые планы могут быть анализироваться сложнее и дольше, чем другие).  \n",
    "\n",
    "Если у нас закончится время после оценки, скажем, 80% точек нашего тщательно построенного оптимального латинского гиперкуба Морриса–Митчелла, не будет никаких гарантий хорошей заполненности пространства полученным подмножеством. В таких случаях часто имеет смысл начать с плана, достаточно небольшого, чтобы безопасно вписаться во временной бюджет, и выбрать последующие точки последовательно (до тех пор, пока не закончится время) на основе моделей, приспособленных к тем точкам, которые у нас уже есть, то есть решить, где какой точкой пополнить план, основываясь на том, какие области кажутся перспективными. Мы подробно обсудим эти процедуры позже; однако, если они по какой-то причине неосуществимы (например, запас времени очень велик, и поэтому повторный процесс подгонки модели может быть непрактичным), существует альтернатива: _последовательности Соболя_ (Sobol, 1994). Это планы выборки с достаточно хорошими свойствами заполнения пространства (по крайней мере, для больших $n$) обладают тем свойством, что для любых $n$ и $k > 1$ последовательность для $n − 1$ и $k$ является подмножеством последовательности для n и k. Таким образом, с точки зрения \"заполненности пространства\" не имеет значения, когда закончится время."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "357px",
    "width": "476px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
