{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суррогатная модель - это аппроксимация, которая дешевле или удобнее для вычисления, чем основополагающа модель. Наиболее распространенным использованием суррогатных моделей является замена известной дорогостоящей вычислительной модели, когда требуется большое количество повторных вычислений. Другое распространенное применение - это когда мы хотим получить непрерывную функцию из фиксированного набора данных, например, полученых экспериментально или из устаревшего кода. Третье приложение - сглаживание основополагающей модели, возможно, для достижения дифференцируемости при оптимизации на основе градиента.  \n",
    "\n",
    "При обсуждении суррогатных моделей полезно разделять построение и оценку модели, поскольку большинство таких моделей имеют параметры, которые предварительно вычисляются на этапе построения. Здесь мы называем оценку модели ___прогнозом___. Учитывая входные данные $n_x$ и параметры $n_w$, прогнозирование представляет собой следующую оценку:  \n",
    "$$y = f(\\mathbf{x}, \\mathbf{w}),$$  \n",
    "где $\\mathbf{x} \\in \\mathbb{R}^{n_x}$ - это входной вектор данных, $y \\in \\mathbb{R}$ - искомая переменная, а $\\mathbf{w} \\in \\mathbb{R}^{n_w}$ - это вектор параметров модели. Мы называем построение модели ___обучением___ и, следовательно, набор данных - ___точками обучения___. Цель обучения состоит в том, чтобы вычислить параметры модели $\\mathbf{w}$, которые удовлетворяют равенству $(1)$ или приближают его как можно лучше:  \n",
    "$$\\bar{y_i} \\approx f(\\bar{\\mathbf{x}}_i, \\mathbf{w}), \\, \\forall 1\\le i \\le n_t$$  \n",
    "где $(\\bar{\\mathbf{x}}_1,\\bar{y_1}), ... , (\\bar{\\mathbf{x}}_{n_t},\\bar{y_{n_t}})$ - это $n_t$ точек обучения.  \n",
    "\n",
    "Из-за своей широкой применимости и полезности суррогатное моделирование было темой активных исследований в течение десятилетий. В инженерном деле кригинг является одним из наиболее часто используемых методов по нескольким причинам. Во-первых, это наиболее точный метод в целом для небольшого или среднего количества обучающих точек ($n_t < 10^3$). Во-вторых, время прогнозирования и обучения кригингу и хорошо пропорционально размерности признакового пространства $n_x$, что позволяет использовать его в задачах с большой размерностью, где $n_x$ может достигать $O(10^2)$. В-третьих, его стохастическая интерпретация помогает оценивать ошибки прогнозирования через дисперсию точек прогнозирования. Однако к недостаткам кригинга относятся увеличение времени прогнозирования с увеличением количества обучающих точек и склонность к провалу обучения, когда тренировочные точки находятся слишком близко друг к другу. Эти недостатки ограничивают максимальное количество обучающих точек, с которыми может справиться кригинг, что, в свою очередь, ограничивает точность, которая может быть достигнута при наличии большого количества тренировочных точек.  \n",
    "\n",
    "В этой статье мы в первую очередь руководствуемся приложениями, в которых суррогатная модель является частью более крупной модели. Например, суррогатная модель может адаптировать аэродинамические характеристики воздушного судна к условиям полета; здесь суррогат является частью многодисциплинарной модели, которая включает другие дисциплины, представленные другими моделями, которые могут быть или не быть суррогатами. Если набор точек обучения фиксирован, то суррогатную модель можно обучить один раз заранее и использовать повторно при каждом запуске мультидисциплинарной модели. Это имеет место во многих задачах многодисциплинарной оптимизации проектирования (MDO), и это побуждает уделять больше внимания времени прогнозирования, чем времени обучения. Другие приложения, такие как оптимизация на основе суррогатов, придают большее значение меньшему времени обучения, поскольку обучение происходит на каждой итерации оптимизации.  \n",
    "\n",
    "Мы разрабатываем новый метод суррогатного моделирования для задач малой размерности ($n_x \\le 4$), который мы называем ___регуляризованными сплайнами тензорного произведения минимальной энергии (regularized minimal-energy tensor-product splines, RMTS)___. RMTS, как правило, обучается медленнее, чем кригинг, но у него быстрое время прогнозирования, которое не увеличивается с увеличением количества обучающих точек. Более того, он может работать с гораздо большим количеством точек, что означает, что при наличии больших наборов данных, например, когда источником данных является быстрая, но недифференцируемая модель, точность, которая может быть достигнута с помощью RMTS, как ожидается, будет выше, чем с помощью кригинга. Интерес к сплайнам тензорного произведения снизился в последние несколько десятилетий из-за их плохого масштабирования по $n_x$; однако современное вычислительное оборудование смягчает эти ограничения масштабирования и позволяет RTMS масштабировать до четырехмерных задач. Более того, сплайны тензорного произведения позволяют прогнозировать на порядки быстрее, чем кригинг, когда количество обучающих точек велико ($n_t > 10^4$). RMTS использует минимизацию энергии и регуляризацию для повышения точности при работе с небольшими наборами данных и для обработки неструктурированных наборов данных, т.е. точек обучения, не расположенных в структурированной сетке.  \n",
    "\n",
    "RMTS доступен по лицензии с открытым исходным кодом как часть _инструментария суррогатного моделирования (surrogate modeling toolbox, SMT)_. Все проблемы сравнительного анализа, а также другие подходы к суррогатному моделированию, рассмотренные в этой статье, включены в репозиторий SMT, поэтому наши результаты полностью воспроизводимы.  \n",
    "\n",
    "Статья организована следующим образом. В разделе 2 мы рассмотрим некоторые методы суррогатного моделирования, которые обычно используются в инженерии: полиномы, сплайны, искусственные нейронные сети, регрессия опорных векторов, взвешивание по обратному расстоянию, радиальные базисные функции и кригинг. В разделе 3 мы представим уравнения и алгоритмы RMTS. В разделе 4 мы будем использовать набор контрольных показателей для оценки RMTS и сравнения методов суррогатного моделирования с точки зрения времени обучения, времени прогнозирования и точности. Мы также обсудим использование RMTS в практическом контексте MDO, связанном с оптимизацией полетов воздушных судов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обзор методов суррогатного моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В инженерном деле суррогатная модель также известна как _поверхность отклика_ или как _метамодель_, отражающая идею о том, что она является моделью основополагающей модели. В этой статье мы используем термин _суррогатная модель_ повсюду, чтобы оставаться последовательными, отмечая при этом, что в других контекстах используются разные термины.  \n",
    "Подходы к суррогатному моделированию можно разделить на _интерполяцию_ (если суррогатная модель соответствует истинному значению функции в каждой точке обучающего набора данных) и _регрессию_ (если это не так). Методы регрессии плавно приближают зашумленные данные и включают в себя полиномы, сплайны, искусственные нейронные сети (artificial neural networks, ANN) и регрессию опорных векторов (support vector regression, SVR). Методы интерполяции пытаются плавно и точно подогнать чистые (незашумлённые) данные, и они включают в себя взвешивание обратного расстояния (inverse distance weighting, IDW), радиальные базисные функции (radial basis functions, RBF) и кригинг. Эти методы широко обсуждаются в литературе Ван и Шан (2007); Симпсон(2008); Форрестер(2008) и др.  \n",
    "\n",
    "Поскольку RMTS классифицируется как метод интерполяции, мы кратко рассмотрим методы регрессии и более подробно объясним методы интерполяции. В разделе 4 представлены результаты сравнения RMTS с IDW, RBF и кригингом, поэтому мы также представим уравнения для каждого из них в том виде, в котором они реализованы для сравнительного анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессионные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полиномиальная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полиномиальная регрессия использует глобальные полиномы низкого порядка от нескольких переменных для аппроксимации обучающих данных. Полиномиальные поверхности отклика были первоначально введены Боксом и Уилсоном (1951). Они обладают преимуществом простоты, что делает их быстрыми и удобными в работе. Однако им не хватает гибкости, и поэтому для многих типов задач они менее точны, чем другие методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сплайны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее успешным методом суррогатного моделирования с использованием сплайнов являются многомерные адаптивные регрессионные сплайны (multivariate adaptive regression splines, MARS), разработанные Фридманом (1991). MARS использует базовые функции, которые кусочно линейны в каждом измерении, и адаптивно разрезает и склеивает базовые функции с помощью жадного алгоритма. MARS хорошо масштабируется с размерностью задачи ($n_x$), но недостатком является то, что время обучения и прогнозирования увеличивается с увеличением количества узлов(что в свою очередь связано с точностью)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Искуственные нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросети работают со взаимосвязанным набором узлов, которые вычисляют функцию активации на основе входных данных, точно так же, как нейроны в мозге срабатывают на основе импульсов. Эти узлы расположены слоями ([персептрон](https://ru.wikipedia.org/wiki/%D0%9F%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD)), где один слой состоит из $n_x$ входов, другой слой состоит из $n_y$ выходов, а остальные слои известны как _скрытые слои_. По сравнению с типичными методами суррогатного моделирования в инженерии, нейронные сети демонстрируют более медленную сходимость. С другой стороны, они способны решать значительно более сложные задачи, такие как распознавание речи и символов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод опорных векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR также имеет свои корни в машинном обучении, но он был успешным в качестве метода для суррогатного моделирования в инженерных приложениях. Обычно он выводится как задача оптимизации, которая находит наиболее “плоское” линейное приближение с заданной точностью. Первоначальное решение использовало скалярное произведение обучающих векторов в целевой функции, а замена этого скалярного произведения другой функцией приводит к общему методу SVR. Выбор функции Гаусса оказывается похожим на RBFs с ядром Гаусса, за исключением того, что он выполняет регрессию с заданным допуском, а не интерполяцию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы интерполяции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Метод обратных взвешенных расстояний](https://desktop.arcgis.com/ru/arcmap/10.4/extensions/geostatistical-analyst/how-inverse-distance-weighted-interpolation-works.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "274px",
    "width": "566px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
